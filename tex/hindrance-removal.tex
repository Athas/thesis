\chapter{Hindrance Removal}
\label{chap:hindrance-removal}

The fusion algorithm presented in previous chapters assumed an input
program with a structure that made any possibilities for fusion as
explicit as possible.  The most obvious such structure is the
normalised input program and the use of tupleless SOACs, but there are
other transformations we can do in order to enable more possibilities
for fusion.

In particular, recall that the fusion algorithm is very strict about
never duplicating computation, and hence multiple uses of the output
of a SOAC may easily block any fusion of the SOAC.  We call such a use
a \textit{hindrance}, with an example shown on
\cref{fig:size-hindrance-blocking}.  In some cases, the hindrances are
unavoidable, but in other cases, a pre-fusion transformation of the
program can remove some unnecessary hindrances.

\begin{figure}
\begin{subfigure}[t]{.5\textwidth}
\begin{colorcode}
let \emp{b} = map(f, a) in
size(0,\emp{b}) + reduce(op +, 0, \emp{b})
\end{colorcode}
\subcaption{Hindrance blocking fusion \label{fig:size-hindrance-blocking}}
\end{subfigure}%
\begin{subfigure}[t]{.5\textwidth}
\begin{colorcode}
let \emp{b} = map(f, a) in
size(0,a) + reduce(op +, 0, \emp{b})
\end{colorcode}
\subcaption{Hindrance removed \label{fig:size-hindrance-removed}}
\end{subfigure}%
\caption{Typical case of \texttt{size}-hindrance}
\label{fig:size-hindrance}
\end{figure}

\Cref{sec:size-hindrance-removal} will cover cases where we can
rewrite \texttt{size}-expressions that reference a SOAC output.
Although primarily concerned with increasing fusibility,
\cref{sec:hoisting-enabler} will describe how removing hindrances can
also enable hoisting, particularly of bounds checks.
\Cref{sec:inlining-indexing} will describe inlining of index
expressions where the index array is the result of a \texttt{map}
operation.  This inlining may duplicate a small amount of computation.

An important detail is that neither of the presented transformations
should be considered optimisations \textit{per se}.  Rather, their
purpose is enable the fusion optimisation to apply more often.

Both transformations are run completely independently (and in advance)
of fusion.  This results in greater conceptual and technical
simplicity, but at some cost in precision.  In particular, the
rewriting of \texttt{size}-expressions can in fact inhibit fusion in
some cases.

\section{Size Hindrance Removal}
\label{sec:size-hindrance-removal}

Consider the program shown on \cref{fig:size-hindrance}.  The output
of the \texttt{map} producer, \texttt{b}, is used in two places - as
input to a consumer \texttt{reduce}, and as argument to a
\texttt{size} expression.  This means that fusing the two SOACs would
duplicate computation, as we be unable to remove the original
\texttt{map} expression.

Fortunately, in this case, we can exploit a property of \texttt{map}
to rewrite the \texttt{size} expression.  Specifically, the outer size
of the array output from a \texttt{map} expression is equal to the
outer size of its array inputs.  In the context of
\cref{fig:size-hindrance}, this means that the expression
\texttt{size(0,b)} will always give the same value as
\texttt{size(0,a)}.  Hence, we can rewrite the program as shown on
\cref{fig:size-hindrance}(\subref{fig:size-hindrance-removed}), which
has now become fusible.

At first glance, removing \texttt{size} hindrances may appear to
rarely be useful, but in fact, it is crucial to making the fusion
algorithm perform well in practice.  The reason is that the assertions
described in \cref{sec:assertions} check the dimensions of various
arrays via \texttt{size} expressions.  Hence, after the transformation
from external to internal \LO{}, we will have generated several
\texttt{size} expressions, many of which may act as hindrances to
fusion.  As an example, consider this simple program:

\begin{colorcode}
fun [int] main([int] a, [int] b) =
  let \emp{a2} = map(op+(1), a) in
  let \emphh{b2} = map(op+(2), b) in
  map(op+, zip(\emp{a2}, \emphh{b2}))
\end{colorcode}

After transformation to internal \LO{}, we obtain the following
(slightly denormalised for readability):

\begin{colorcode}
fun [int] main([int] a, [int] b) =
  let \{\emp{a2}\} = mapT(op + (1), a) in
  let \{\emphh{b2}\} = mapT(op + (2), b) in
  let a2_sz = size(0, \emp{a2}) in
  let b2_sz = size(0, \emphh{b2})) in
  let zip_assert = assert(a2_sz = b2_sz) in
  let \{res\} = <zip_assert>mapT(op + \emp{a2}, \emphh{b2}) in
  res
\end{colorcode}

Two \texttt{size}-hindrances are present.  Since \texttt{a2} and
\texttt{b2} are the outputs of mapping over \texttt{a} and \texttt{b}
respectively, we can rewrite \texttt{size(0,a2)} to \texttt{size(0,a)}
and \texttt{size(0,b2)} to \texttt{size(0,b)}, thus removing the
nuisances and turning the program fusible.

Our chosen approach is quite simple: Traverse the program, and
whenever an expression of the form \texttt{size($k$,$v$)} is
encountered, see if it can be rewritten to a ``better'' form.  In most
cases, we will have several alternative expressions to choose from,
and hence we need a way to determine the best replacement.

For our purposes, we will want the expression that has the least
chance of being a hindrance to fusion.  As noted in the introduction
to this chapter, hindrance removal is done outside of the fusion
module, and hence we do not have access to precise information about
whether a candidate replacement expression removes a potential
hindrance, or perhaps even moves it.
\Cref{sec:accidentally-adding-hindrances} will describe cases in which
moving \texttt{size}-expressions may cause new hindrances to appear.

It is conceptually simple to generate alternatives to the expression
\texttt{size($k$,$v$)}.  During traversal of the program, we track the
binding of all array-typed variables in a symbol table mapping
variable names to static size information.  For example, after seeing
the binding \texttt{let~a~=~iota($e$)}, we know that
\texttt{size(0,a)} can be rewritten to \texttt{$e$}.  The details of
size analysis are described in \cref{sec:size-analysis}.  However, in
some cases there may be several possible replacement expressions, and
we need a way to select the best one.

We define a heuristic determining the \textit{quality} of a candidate
expression $e$ as follows: For every free variable $v_{i}$ in $e$,
determine the data-flow path from $v_{i}$ to either a constant or a
function parameter.  The quality of the expression is inversely
proportional to the number of nodes in this path, exluding nodes that
are simply copies or indexing.  That is, the expression with the
lowest number is best.  The idea behind this heuristic is to choose
the expression that we can move the furthest up the program, ideally
preceding all SOACs.

For example, for the program shown on
\cref{fig:multiple-replacements}, the hindrance \texttt{size(0, c)}
can be replaced with either \texttt{size(0, b)} or \texttt{size(0,
  a)}.  We pick the latter, because its single free variable can be
traced directly to a function parameter (\texttt{a}), whereas the free
variable in the former can only reach a function parameter through the
binding for \texttt{b}.

\begin{figure}
\begin{center}
\begin{bcolorcode}
fun [int] main([int] a) =
  let b = map(op + (1), a) in
  let c = map(op + (2), b) in
  let n = size(0, c) in
  let d = map(op + (n), c) in
  d
\end{bcolorcode}
\end{center}
\caption{Multiple potential hindrance replacements}
\label{fig:multiple-replacements}
\end{figure}

In the \LO{} compiler, size hindrance removal is implemented as part
of the Rebinder introduced in \cref{sec:rebinder}.  Array sizes are
tracked by inspecting bindings during the traversal of the syntax
tree, as described in the next section.  Whenever we encounter a
binding of a \texttt{size}-expression, we use the size information to
obtain candidate replacements, then use the quality heuristic to
determine the best replacement.

\subsection{Size analysis}
\label{sec:size-analysis}

To aid in rewriting \texttt{size} expressions, the Rebinder maintains
a symbol table mapping variables to size information.  The size
analysis presented in this section is an entirely \textit{ad hoc}
mechanism focused solely on the removal of \texttt{size} nuisances.
More sophisticated size analysis, which could be used to optimise
memory allocation in the code generator, is left as a future project.

The size information we store takes the form of a sequence of sets of
expressions, with the set at index $i$ representing the various
expressions that evaluate to the size of that dimension.  For example,
we may have the following mapping in the symbol table:
\[
a \mapsto \langle\{10\}, \emptyset, \{\texttt{size(0,$b$)}, \texttt{size(1,$c$)}\}]
\]
This indicates that the the first dimension of $a$ has size $10$, we
know nothing of the second dimension, and the size of the third
dimension is equal to the first dimension of $b$ or the second
dimension of $c$.  If the symbol table contains bindings for $b$ and
$c$, we can look them up recursively and find even more accurate size
information.

If a mapping refers to an array variable with $n$ dimensions, the
mapping may contain less than $n$ sets.  This implicitly means that we
know nothing (i.e. $\emptyset$) about the excess dimensions.

The mappings generated by different bindings are given below.  Note
that not all bindings generate a mapping; this means that the symbol
table does not necessarily include size information for all variables
in scope.

\begin{description}
\item[\texttt{let $a$ = iota($e$)}] \hfill\\
  $a \mapsto \langle\{e\}\rangle$

\item[\texttt{let $a$ = replicate($e_{n}$, $e_{v}$)}] \hfill\\
  We know that the number of rows in $a$ is $e_{n}$, but we also know
  that the size of dimension $d$ of $a$ will be the size of dimension
  $d+1$ in $e_{v}$.  This is reflected in the size binding:

  $a \mapsto \langle\{e_{n}\}, \{\texttt{size(0,$e_{v}$)}\}, \ldots,
  \{\texttt{size($n$,$e_{v}$)}\}\rangle$, where $n$ is the rank of
  $e_{v}$.

\item[\texttt{let \{$a$,$b$\} = split($e_{n}$, $e_{v}$)}] \hfill\\
  The semantics of \texttt{split($e_{n}$, $e_{v}$)} is that the first
  returned array contains the initial $e_{n}$ elements, while the
  remaining \texttt{size(0,$e_{v}$)-$e_{n}$} are in the the second
  returned array.  This leads to the following size bindings:

  $a \mapsto \langle\{e_{n}\}, \{\texttt{size(1,$e_{v}$)}\}, \ldots, \{\texttt{size(n,$e_{v}$)}\rangle$\\
  $b \mapsto \langle\{\texttt{size(0,$e_{v}$)}-e_{n}, e_{n}\},
  \{\texttt{size(1,$e_{v}$)}\},
  \ldots, \{\texttt{size(n,$e_{v}$)}\rangle$\\
  Where $n$ is the rank of $e_{v}$.

\item[\texttt{let $a$ = concat($e_{x}$, $e_{y}$)}] \hfill\\
  $a \mapsto \langle\{\texttt{size(0,$e_{x}$)+size(0,$e_{y}$)}\},
  \{\texttt{size(1,$e_{x}$)}, \texttt{size(1,$e_{y}$)}\}, \ldots,
  \{\texttt{size(n,$e_{x}$)}, \texttt{size(n,$e_{y}$)}\rangle$, where
  $n$ is the rank of $e_{x}$ and $e_{y}$ (the same, according to the
  type rules of \LO{}).

\item[\texttt{let $a$ = $b$[$e_{0},\ldots,e_{n}$]}] \hfill\\
  $a \mapsto \langle\{\texttt{size($n+1$,$b$)}\}, \ldots, \{\texttt{size($m$,$b$)}\}\rangle$, where $m$ is
  the rank of $b$.

\item[\texttt{let $a$ = transpose($e$)}] \hfill\\
  $a \mapsto \langle\{\texttt{size(1,$e$)}\},
  \{\texttt{size(0,$e$)}\}, \{\texttt{size(2,$e$)}\}, \ldots,
  \{\texttt{size($n$,$b$)}\}\rangle$, where $n$ is the rank of $b$.

\item[\texttt{let $a$ = $b$ with [\ldots] <- $e$}] \hfill\\
  $a \mapsto \langle\{\texttt{size(0,$b$)}\}, \ldots, \{\texttt{size($n$,$b$)}\}\rangle$, where $n$ is the
  rank of $b$.

\item \texttt{let \{$a_{1},\ldots,a_{k}$\} = mapT(fn $t$ ($p_{1},\ldots,p_{n}$) => $e$, $e_{1}$, \ldots, $e_{n}$)} \hfill\\
  Within the body of the SOAC function ($e$), the symbol table will
  map the parameters to row slices of their corresponding arrays:

  $p_{1} \mapsto \langle\{\texttt{size(1, $e_{1}$)}\}, \ldots, \{\texttt{size(m, $e_{1}$)}\}\rangle$, where $m$ is the rank of $e_{1}$. \\
  $\vdots$\\
  $p_{n} \mapsto \langle\{\texttt{size(1, $e_{n}$)}\}, \ldots, \{\texttt{size($m$, $e_{n}$)}\}\rangle$, where $m$ is the rank of $e_{n}$. \\

  Additionally, we know by the semantics of \texttt{mapT} that the
  outer size of any $a_{i}$ must match the outer size of any $e_{j}$.
  This gives rise to the following mappings:

  $a_{1} \mapsto \langle\{\texttt{size(0, $e_{j}$)}\ |\ 1 \leq j \leq n\}\rangle$. \\
  $\vdots$\\
  $a_{k} \mapsto \langle\{\texttt{size(0, $e_{j}$)}\ |\ 1 \leq j \leq n\}\rangle$. \\

  Similar rules apply to the other SOACs, but a few are interesting
  enough to be mentioned explicitly.

\item \texttt{let \{$a_{1},\ldots,a_{k}$\} = mapT$\myindu{d}$(fn $t$ ($p_{1},\ldots,p_{n}$) => $e$, $e_{1}$, \ldots, $e_{n}$)} \hfill\\
  We create the same bindings as above for the function parameters,
  but the interesting fact is that since we are dealing with a
  $d$-deep mapping, the outer $d$ dimensions of the output correspond
  to the outer $d$ dimensions of the input.  This gives rise to the
  following mappings:

  $a_{1} \mapsto \langle\{\texttt{size(0, $e_{j}$)}\ |\ 1 \leq j \leq n\}, \ldots, \{\texttt{size($d$, $e_{j}$)}\ |\ 1 \leq j \leq n\}\rangle$. \\
  $\vdots$\\
  $a_{k} \mapsto \langle\{\texttt{size(0, $e_{j}$)}\ |\ 1 \leq j \leq n\}, \ldots, \{\texttt{size($d$, $e_{j}$)}\ |\ 1 \leq j \leq n\}\rangle$. \\

\item \texttt{let \{$a_{1},\ldots,a_{n}$\} =\\scanT(fn $t$ ($p^{v}_{1},\ldots,p^{v}_{n}$, $p^{a}_{1},\ldots,p^{a}_{n}$) => $e$, \{$v_{1},\ldots,v_{n}$\}, $e_{1}$, \ldots, $e_{n}$)} \hfill\\
  Within the body of the SOAC function ($e$), the symbol table will
  map the parameters to row slices of their corresponding arrays.
  Additionally, by the semantics of \texttt{scanT}, we know that the
  inner size of $e_{i}$ must be equal to the outer size of $v_{i}$:

  $p^{a}_{1} \mapsto \langle\{size(1, e_{1}), \texttt{size(0, $v_{1}$)}\}, \ldots, \{size(m, e_{1}), \texttt{size($m-1$, $v_{1}$)}\}\rangle$, where $m$ is the rank of $e_{1}$. \\
  $\vdots$\\
  $p^{a}_{n} \mapsto \langle\{size(1, e_{n}), \texttt{size(0, $v_{n}$)}\}, \ldots, \{size(m, e_{n}), \texttt{size($m-1$, $v_{n}$)}\}\rangle$, where $m$ is the rank of $e_{n}$. \\

  Additionally, we also know by the semantics of \texttt{scanT} that
  the outer size of any $a_{i}$ must match the outer size of any
  $e_{j}$.  This gives rise to the following mappings:

  $a_{1} \mapsto \langle\{\texttt{size(0, $e_{j}$)}\ |\ 1 \leq j \leq n\}\rangle$. \\
  $\vdots$\\
  $a_{n} \mapsto \langle\{\texttt{size(0, $e_{j}$)}\ |\ 1 \leq j \leq n\}\rangle$. \\
\end{description}

There is no rule for the binding of array literals - this is handled
by the constant folder presented in \cref{sec:copyconstpropfold}.
Furthermore, a \texttt{size} expression depending on an array literal
binding will not ever inhibit fusion.

\subsection{Accidentally Adding Hindrances}
\label{sec:accidentally-adding-hindrances}

In some cases, our aggressive rewriting of \texttt{size} expressions
may in fact \textit{create}, rather than \textit{remove} hindrances.
Consider the following program:

\begin{colorcode}
let b = map(f, a) in
let c = map\(\myindu{2}\)(g, b) in
let k = size(1,c) in
h(k,c)
\end{colorcode}

Here, there is a clear opportunity for fusing the two \texttt{map}s.
Note that the function \texttt{f} is opaque, and we cannot know the
size of the arrays it returns.  Since \texttt{c} is the result of a
\texttt{map\(myindu{2}\)} operation, the Rebinder can change
\texttt{size(1,c)} to \texttt{size(1,b)}, resulting in the following
program:

\begin{colorcode}
let b = map(f, a) in
let k = size(1,b) in
let c = map\(\myindu{2}\)(g, b) in
h(k,c)
\end{colorcode}

The \texttt{size} expression is now a nuisance preventing fusion.  One
possible solution, and the one taken in the current \LO{} compiler, is
a preliminary fusion stage, prior to executing the Rebinder, then run
the Rebinder and re-run fusion.  A more precise solution would be to
integrate nuisance removal into the fusion algorithm, but this
requires careful engineering in order to keep the resulting compiler
code complexity under control.  Alternatively, it may be possible to
tweak the rules in the Rebinder to remove the possibility of creating
fusion hindrances, although this has not been investigated in depth.

\subsection{Size Hindrance Removal as a Hoisting Enabler}
\label{sec:hoisting-enabler}

This section has been solely concerned with \texttt{size} nuisance
removal as a transformation to enable fusion.  However, it is equally
useful in enabling hoisting.  Consider the following program:

\begin{colorcode}
mapT(fn \{[int]\} ([int] ar, [int] br) =>
       let c = assert(size(0,ar) == size(0,br)) in
       mapT<c>(op +, ar, br),
     a, b)
\end{colorcode}

Size analysis will reveal that \texttt{size(0,ar)} can be rewritten to
\texttt{size(1,a)}, and \texttt{size(0,br)} to \texttt{size(1,b)},
which can then be hoisted out of the loop.  This results in the
following program:

\begin{colorcode}
let c = assert(size(1,ar) == size(1,br)) in
mapT(fn \{[int]\} ([int] ar, [int] br) =>
       mapT<c>(op +, ar, br),
     a, b)
\end{colorcode}

Not only does this result in removing the assertion from the inner
loop, but the result is a perfect map nest, potentially permitting
fusion across transpose.

\section{Inlining of indexing}
\label{sec:inlining-indexing}

The fusion algorithm presented in \cref{chap:fusion} is very strict
about never duplicating computation, to the point where otherwise
beneficial fusion is prevented.  For example, consider this program:

\begin{colorcode}
let b = map(f, a) in
reduce(min, b[0], b)
\end{colorcode}

Fusion is not possible, as \texttt{b} is used in multiple places.  If
duplication of computation were acceptable, we could rewrite
\texttt{b[0])} as \texttt{f(a[0])}, and get the following program:

\begin{colorcode}
let b = map(f, a) in
reduce(min, f(a[0]), b)
\end{colorcode}

We could then perform \texttt{map}-\texttt{reduce} fusion and obtain a
fully fused \texttt{redomap} expression.  If \texttt{f} is cheap, it
is very likely that the small duplication of computation is
worthwhile.

Similarly to size hindrance removal, we can implement this as a
transformation performed before running the fusion algorithm.
Specifically, when we find an expression of form \texttt{b[i]}, where
\texttt{b} is the result of an expression \texttt{map(f, a)} and
\texttt{f} is \textit{cheap} (see below), we rewrite \texttt{b[i]} to
\texttt{f(a[i])}, essentially inlining part of the \texttt{map}
operation.

A function is considered cheap if its body executes in constant time -
notably, no SOACs.  We must also be careful not to inline into a loop,
as this would duplicate more than a constant amount of computation.
This implies that every such instance of inlining at most results in
duplicating a constant amount of work.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
