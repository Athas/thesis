\chapter{Introduction}

For practically the entire lifetime of the electronic computer,
programmers have been used to an exponential growth in commonly
available computing power.  Until around 2006, this directly
manifested itself as improvements to sequential performance, although
physical limits made it uneconomical (or impossible) for this trend to
continue.  These days, hardware designers are making their machines
increasingly \textit{parallel}: rather than speeding up the individual
processors, as happened previously, \textit{more} processors, or more
\textit{specialised} processors, are added.  Thus, while computing
power is still growing, it has become increasingly necessary to write
programs that are parallel in order to take full advantage of modern
hardware.

One interesting development is the commoditisation of massively
parallel vector processors in the form of graphics cards.  While
hardware acceleration of graphics became commonplace in the 90s, it
was not until the rise of CUDA and OpenCL in 2006 that
\textit{General-Purpose computing on Graphics Processing Units}
(GPGPU) began to move into the mainstream.

... \fxnote{Insert more - convince reader that my work addresses an
  important problem, and that I will give a well thought-out solution.
  Why is \LO{} functional, and why does it support sequential loops
  anyway?}

Throughout this thesis, we will often refer to a vaguely defined
``programmer'', as well as ascribe various motives and expectations to
this nebulous being.  While \LO{} is intended as an intermediate
language, and in the end is intended as a target language by compilers
for higher-level languages, it has a well-defined human-readable (and
writable) syntax, and can be programmed directly.  Indeed, all extant
\LO{} programs have been written by hand.  Thus, when ``the
programmer'' is referenced, we can refer to either an actual human, or
a compiler generating \LO{} code.  For our purposes, these will have
identical motives, although a human programmer may complain somewhat
more vocally about the lack of syntactical niceties in the language.

\section{Contributions}

We present a purely functional data-parallel programming language,
\LO{}, supporting nested parallelism.  The language supports a method
\fixme{Why do I support nested parallelism?  Why only regular arrays?
  Why are in-place updates supported (cross-iteration dependent
  loops)} for safely performing in-place updates of array data through
a type system concept called \textit{uniqueness types}.  Through the
translation of real-world financial programs to \LO{}, we demonstrate
the practical usefulness of this language feature.

We present the design and implementation of several optimisations,
notably hoisting bounds checks out of inner loops, and loop fusion
based on a structural transformation.  The fusion transformation is
capable of fusing loops whose output is used in multiple places, when
possible without duplicating computation.\fixme{Why is it important to
  hoist bounds checks?  Because we target aggressive (static+dynamic)
  analysis; this is an instance of optimising arbitrary predicates.}

The benefits of our optimisations are demonstrated on three real-world
financial benchmarks.  It is shown that the compiler is able to hoist
bounds checks and other assertions outside of loops.

The effectiveness of fusion is demonstrated via compiler
instrumentation and quantitative and qualitative measurements on the
three benchmarks, in the form of inspecting the changes in program
dataflow.  This shows that always refusing to duplicate computation is
too conservative on parallel hardware, and discuss potential
directions for further improvement.

The implementation of the \LO{} compiler consists of roughly ten
thousand lines of Haskell (ignoring comments and blank lines), and it
is hosted and publicly browsable at
\url{https://github.com/HIPERFIT/L0Language}.

Parts of this thesis, in particular the core of the fusion algorithm
in \cref{chap:fusion}, has been previously published as

\begin{quote}
\fullcite{Henriksen:2013:TGA:2502323.2502328}
\end{quote}

\section{Report outline}

The remainder of the report is structured as follows.
\Cref{chap:l0language,chap:uniqueness-types} will introduce the
programmer-visible part of \LO{} and serves as a language reference.
\Cref{chap:internal} presents a slight modification of the external
language, that makes it more amenable to transformation and
optimisation.  \Cref{chap:first-order-optimisations} discusses various
classical optimisations in the context of \LO{}.  \Cref{chap:fusion}
covers \textit{loop fusion}, an important optimisation, while
\cref{chap:fusion-enabling-soac-transformations,chap:hindrance-removal}
cover transformations that enable other optimisations (although
particularly fusion).

\section{Notation}

In various places, I will use an \(\overline{\text{overline}}\) to
indicate a comma-separated sequence of terms.  For example, when
describing a function call, rather than writing:
\[
f(e_{1},\ldots,e_{n})
\]
I may instead write:
\[
f(\overline{es})
\]
I may also use this in conjunction with expliclt arguments, as in:
\[
f(e_{start},\overline{es},e_{end})
\]

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
