\chapter{Internal representation}
\label{chap:internal}

It is a common compilation technique to transform the externally
visible language into a simpler intermediate language, on which all
optimisation and further compilation is performed.  This is usually
necessary, because languages written for human consumption have a
large amount of bells and whistles that make programming more
convenient, but offer no significant avenues for optimisation, but
rather just leave more cases for the optimiser to handle.

We do not suffer as badly from that problem with \LO{}, as it was
designed as an intermediate language itself.  Nevertheless, before
embarking on any optimisation, we do transform the input program to an
internal dialect of \LO{}.  In most compilers, it is usually not
possible to transform the intermediate language to the external
language, at least not without losing much of the structure of the
original program.  In comparison, the transformation from external to
internal \LO{} is comparatively simple and reversible (with some loss
of information; see \cref{sec:internal-to-external}).

A very important first notice: All names in internal \LO{} are
\textit{globally unique}.  This means that we will never have name
shadowing, and we can uniquely identify, say, a \texttt{let}-binding
by one of the names it binds.

\section{Tuple transformation}
\label{sec:tuple-transformation}

The principal difference between external and internal \LO{} is the
total absence of arrays of tuples in the latter.  There are several
reasons for this - \cref{chap:fusion} will describe how this benefits
the fusion algorithm, and when generating the final machine code, we
will also not be able to conveniently represent arrays of tuples in
memory.

An array of tuples type is converted to a tuple containing arrays of
the original tuple components, for which the process is then repeated
recursively.  Futhermore, tuples are flattened.  All other types are
left unchanged.  A few examples:

\begin{align*}
\texttt{[int]} &\Rightarrow \texttt{[int]} \\
\texttt{[\{int,real\}]} &\Rightarrow \texttt{\{[int],[real]\}} \\
\texttt{[\{[int], real\}]} &\Rightarrow \texttt{\{[[int]], [real]\}} \\
\texttt{\{\{int, bool\}, real\}} &\Rightarrow \texttt{\{int, bool, real\}} & \text{(Flattening)} \\
\end{align*}

\texttt{zip} and \texttt{unzip} are not allowed in internal \LO{}.
Both are removed during the conversion process, as they perform a
transformation between representations that is not necessary in
internal \LO{}, although \texttt{zip} has some additional
complications that are discussed in \cref{sec:assertions}.

Most expressions operating on arrays of tuples have to be modified to
operate on the components of the replacement tuples-of-arrays instead,
but the transformation is relatively trivial, so we will not describe
it in detail.

Internal \LO{} also does not permit tuple-typed variables.  Hence,
every pattern that binds a variable to a tuple must be converted to
explicitly name the elements of the tuple, e.g:

\begin{colorcode}
let x = \{f(a), g(b)\} in
...
  \(\emp{\Downarrow}\)
let \{x1,x2\} = \{f(a), g(b)\} in
...
\end{colorcode}

\subsection{Tupleless SOACs}

As internal \LO{} does not permit tuples of arrays, we need to find a
way to convert an expression such as:
\begin{colorcode}
map(fn int ({int,int} t) =>
      let {x,y} = t in
      f(x,y),
    zip(a, b))
\end{colorcode}
The solution is tupleless SOACs: variants of the normal SOACs in which
several arrays are traversed in parallel.  For example, the previous
expression will be converted to:
\begin{colorcode}
mapT(fn \{int\} (int x, int y) =>
       f(x,y),
     a, b)
\end{colorcode}
Conceptually, we can imagine that the tuple-SOACs all have a built-in
\texttt{zip}.  Furthermore, initial values for tuple-typed
accumulators (for \texttt{reduceT}, \texttt{scanT} and
\texttt{redomapT}) are given element-wise, and also passed
element-wise to the function.  This, combined with the ban on arrays
of tuples, implies that no parameter of a function in a tupleless SOAC
is ever tuple-typed.

\begin{figure}[bt]
\begin{tabular}{lrll}
$e$ & $::=$ & \texttt{<$c$>mapT(fn $t$ ($t_{1}$ $v_{1}$, \ldots, $t_{n}$ $v_{n}$) => $e_f$, $e_{1}$, \ldots, $e_{n}$)} \\
    & $|$ & \texttt{<$c$>filterT(fn $t$ ($t_{1}$ $v_{1}$, \ldots, $t_{n}$ $v_{n}$) => $e_f$, $e_{1}$, \ldots, $e_{n}$)} \\
    & $|$ & \texttt{<$c$>reduceT(fn $t$ ($t_{1}$ $v_{1}$, \ldots, $t_{n}$ $v_{n}$) => $e_f$, \{$x_{1}$, \ldots, $x_{n}$\}, $e_{1}$, \ldots, $e_{n}$)} \\
    & $|$ & \texttt{<$c$>scanT(fn $t$ ($t_{1}$ $v_{1}$, \ldots, $t_{n}$ $v_{n}$) => $e_f$, \{$x_{1}$, \ldots, $x_{n}$\}, $e_{1}$, \ldots, $e_{n}$)} \\
    & $|$ & \texttt{<$c$>redomapT(fn $t_{o}$ ($t_{o_{1}}$ $v_{o_{1}}$, \ldots, $t_{o_{n}}$ $v_{o_{n}}$) => $e_o$,} \\
    &     & \texttt{\ \ \ \ \ \ \ \ \ \ \ \ fn $t_{i}$ ($t_{i_{1}}$ $v_{i_{1}}$, \ldots, $t_{i_{n}}$ $v_{i_{n}}$) => $e_i$,} \\
    &     & \texttt{\ \ \ \ \ \ \ \ \ \ \ \ \{$x_{1}$, \ldots, $x_{n}$\}, $e_{1}$, \ldots, $e_{n}$)} \\
\end{tabular}
\caption{Tupleless Second-order array combinators}
\label{fig:tupleless-soacs}
\end{figure}

As a minor detail, curried functions are also not permitted in
tupleless SOACs, although we will still use them for notational
convenience.  The notation is summarised on \cref{fig:tupleless-soacs}
- the \texttt{<$c$>} notation is explained in the next section.

\section{Assertions}
\label{sec:assertions}

Removal of \texttt{zip} carries with it an additional complication.
Recall that \texttt{zip} is responsible for checking that the input
arrays are of the same (outer) size, and if they are not, terminate
the program with an error.  The obvious solution is to make each
tupleless SOAC do the same check, but that would be wasteful of
computer resources.  Even worse, it's not a full solution to the
problem.  Consider the following expression.
\begin{colorcode}
let c = zip(a,b) in
c[0]
\end{colorcode}
How should this be transformed?  There is an obvious solution:
\begin{colorcode}
\{a[0], b[0]\}
\end{colorcode}
But it is of course wrong - there is no checking that \texttt{a} and
\texttt{b} are of the same length, hence the original expression may
fail, while the transformed expression may evaluate successfully.  The
final solution is to \textit{predicate} the expression on the fact
that \texttt{a} and \texttt{b} must match.
\begin{colorcode}
if \textit{\texttt{a} and \texttt{b} have the same length}
then \{a[0], b[0]\}
else \textit{fail}
\end{colorcode}
Using branches to accomplish this somewhat complicates further
transformation and optimisation however, so an approach based on
\textit{assertions} was chosen.  First, we introduce a new type,
\texttt{cert}, which is inhabited by only one value \texttt{Checked}.
The idea is that a value of type \texttt{cert} acts as a
\textit{certificate}, certifying that some property has been checked.
We then add three new language constructs:

\begin{description}
\item[\texttt{assert($e$)}]\hfill\\
  Returns \texttt{Checked} if the boolean expression $e$ returns
  \texttt{True}, otherwise terminates the program with an error.

\item[\texttt{conjoin($e_{1}, \ldots, e_{n}$)}]\hfill\\
  All of $e_{1}, \ldots, e_{n}$ must be expressions of type
  \texttt{cert}.  Always returns \texttt{Checked}.  The purpose of
  \texttt{conjoin} is to combine several \texttt{cert} values into
  one.

\item[\texttt{<$v_{1},\ldots,v_{n}$>$e$}]\hfill\\
  A predicated expression.  Evaluate $e$ and return its value.  The
  variables $v_{1},\ldots,v_{n}$ are certificates: variables that must
  each be of type \texttt{cert}.  They exist solely to express a
  dependency between the expression $e$ and whichever assertions it is
  predicated upon, which implies that on any execution path leading to
  $e$, the assertions computing the certificates will have been
  executed first.
\end{description}

Now the index expression given above can be transformed into the
following.

\begin{colorcode}
let c = assert(size(0,a) = size(0,b)) in
\{<c>a[0], <c>b[0]\}
\end{colorcode}

An advantage of this approach is that the association between
assertions and predicated expressions is given by the same
variable-usage rules that govern all other expressions, and it is
therefore not necessary to handle \texttt{assert} specially in the
various transformations.  It is, however, necessary to maintain the
list of certificates when transforming a predicated expression, but it
turns out that this is simple in practice.  Essentially, the rule is
that every expression derived one or more predicated expressions must
be predicated likewise.

The assertion design also has the particularly convenient property
that even if later transformations pick apart the tuple literal, the
individual components will still be predicated on the original
property.  Even more importantly, the condition \texttt{size(0,a) =
  size(0,b)} is seen as a perfectly ordinary expression by the rest of
the compiler, and can be simplified (or removed altogether) by size
analysis, copy propagation, constant folding, common-subexpression
elimination and other standard optimisations.

One thing is worth noting: The assertion expression, or the value that
it computes, has no recognisable meaning by itself.  It is not a
proposition in the sense of formal logics, and we can only determine
which property it guarantees by the way in which it is used.  This
limits what kinds of information the compiler can deduce from an
assertion, compared to using a real theorem prover or dependent type
system.  In particular, we can perform only very limited static
checking, where through simplification we are able to obtain the
expression \texttt{assert(False)}, although even then we cannot be
certain that the assertion is not dead code.  Hence, the assertion
system functions solely at run-time.  Nevertheless, the
power-to-weight ratio is very high for this design, and it suits our
purpose well.

Having introduced an assertion mechanism to solve the problem of
tupleless SOACs, it is of course worth to consider whether it can be
used for other purposes as well.  As it turns out, we can use
assertions to express bounds-checking (using a somewhat ugly syntax):

\begin{minipage}{0.1\columnwidth}
\begin{center}
\begin{colorcode}
a[i]
\end{colorcode}
\end{center}
\end{minipage}
$\Rightarrow$
\begin{minipage}{0.46\columnwidth}
\begin{center}
\begin{colorcode}
let c = assert(0 <= i && i < size(0,a)) in
a[<c> | i]
\end{colorcode}
\end{center}
\end{minipage}

Again, what we gain is the ability to exploit our standard
expression-optimisation machinery to simplify and perhaps even remove
the bounds check.  In particular, range analysis can be used to hoist
such expressions out of inner loops - all the while staying within the
(internal) \LO{} language.  This will be covered in greater detail in
\cref{sec:hoisting}.

\begin{figure}[bt]
\begin{tabular}{lrll}
$t$ & $::=$ & \texttt{cert} & (Certificate) \\
\\
$k$ & $::=$ & \texttt{Checked} & (Always-true certificate) \\
\\
$c$ & $::=$ & $v_1, \ldots ,v_{n}$ & (Sequence of variables) \\
\\
$e$ & $::=$ & \texttt{assert($e$)} & (Assertion) \\
& $|$ & \texttt{conjoin($e_{1}$, \ldots, $e_{n}$)} & (Conjoin assertions) \\
& $|$ & \texttt{<$c$>\textbf{id}[$e_{1}$, \ldots, $e_{n}$]} & (Indexing) \\
& $|$ & \texttt{<$c$>size($k$, $e$)} & (Array length) \\
& $|$ & \texttt{<$c$>reshape(($e_{1}$,\ldots,$e_{n}$), $e$)} & (Array reshape) \\
& $|$ & \texttt{<$c$>transpose($e$)} & (Transposition) \\
& $|$ & \texttt{<$c$>split($e_{1}$, $e_{2}$)} & (Split $e_{2}$ at index $e_{1}$) \\
& $|$ & \texttt{<$c$>concat($e_{1}$, $e_{2}$)} & (Concatenation) \\
& $|$ & \texttt{let <$c$>$v_{1}$ = $v_{2}$ with} & (In-place update) \\
&     & \texttt{\ \ [<$c$>|$e_{1}$,\ldots,$e_{n}$] <- $e_{v}$} \\
&     & \texttt{in $e_{b}$} \\
& $|$ & \texttt{$v$[<$c$>|$e_{1}$, \ldots, $e_{n}$]} & (Indexing) \\
\end{tabular}
\caption{Assertions}
\label{fig:assertions}
\end{figure}

\subsection{Function Calls}

One question is left - namely how functions mesh with the assertion
system.  One solution is to simply require function calls to be
predicated.  That is, the program
\begin{colorcode}
fun [int] f([\{int,int\}] input) =
  map(op+, input)

f(zip(a,b))
\end{colorcode}
is converted into
\begin{colorcode}
fun [int] f([int] input1, [int] input2) =
  mapT(op +, input1, input2)

let c = assert(size(0,a) = size(0,b)) in
f<c>(a,b)
\end{colorcode}

This is satisfactory from the point of view of the caller - the
function \texttt{f} (after undergoing transformation) has the
precondition that \texttt{a} and \texttt{b} are of the same size, and
this is indeed checked by the above call.  The body of the function is
slightly more dubious, as \texttt{mapT} is invoked without a
certificate that its inputs are of the same size, but as long as the
caller takes care to only invoke the function when this precondition
is satisfied (which we do in the above case), all will be well.

The real problem occurs if we inline \texttt{f}.  If we do it naïvely,
we get this program:
\begin{colorcode}
let c = assert(size(0,a) = size(0,b)) in
mapT(op +, a, b)
\end{colorcode}
And \textit{now} we have a problem -- \texttt{c} is not used anywhere,
and may thus be moved to after the \texttt{mapT} expression, or maybe
even removed as dead code!  This is bad.  A possible solution would be
to make the inliner smarter, and modify the inlined function body such
that every leaf of its syntax tree is predicated on the same
certificates as the original function call.  This is a rather clumsy
solution however, and may cause unnecessary predication on branches of
the function that do not depend on the precondition, which would
inhibit some transformations, like hoisting.  A more fine-grained
solution is needed.

That solution is to embed the certificates directly into the parameter
list of the function.  A function that originally accepted a single
parameter of type \texttt{[\{int,int\}]} will, after conversion to
internal \LO{}, accept three parameters of types \texttt{cert},
\texttt{[int]}, \texttt{[int]}.  The example given at the beginning of
the section will become:
\begin{colorcode}
fun [int] f(cert input_c, [int] input1, [int] input2) =
  mapT<input_c>(op +, input1, input2)

let c = assert(size(0,a) = size(0,b)) in
f(c, a,b)
\end{colorcode}
Naïve inlining will produce:
\begin{colorcode}
let c = assert(size(0,a) = size(0,b)) in
mapT<c>(op +, a, b)
\end{colorcode}
Which is the desired result.

Return values can be handled in a similar fashion.  The program
\begin{colorcode}
fun [\{int,int\}] f(int x) =
    zip(iota(x), iota(x))

let a = f(10) in
map(g,a)
\end{colorcode}
is converted into
\begin{colorcode}
fun \{cert, [int], [int]\} f(int x) =
  let v1 = iota(x) in
  let v2 = iota(x) in
  let c = assert(size(0, v1) = size(0, v2)) in
  \{c, v1, v2\}

let \{c, a1, a2\} = f(10) in
mapT<c>(g, a1, a2)
\end{colorcode}

The return type of \texttt{f} has been modified to include a
certificate for the postcondition that the two return arrays have the
same outer size.\footnote{In this specific case, later simplification
  will eventually result in the assertion being removed and replaced
  with the literal \texttt{Checked}, but it has been retained for
  clarity in this example.}

This solution requires a large amount of tedious tracking of
certificates in the module that converts external to internal \LO{},
but as a tradeoff, the rest of the compiler can be kept simpler, as
all dependencies between predicated expressions and assertions are
explicit.

\section{Converting from Internal to External \LO{}}
\label{sec:internal-to-external}

The internal language matches the external quite closely;
nevertheless, the transformation from external to internal language
does not have a fully defined inverse.  That is, given a program in
internal \LO{}, we can compute an equivalent program in external
\LO{}, but it might not be the original program.  The steps are simple
in principle:

\begin{enumerate}
\item Convert tupleless SOACs to ordinary SOACs, \texttt{zip}ping the
  arguments and \texttt{unzip}ping the return value.

\item Remove all expressions and bindings of type \texttt{cert},
  including function parameters.

\item Remove predicates from all predicated expressions.

\item Remove all \texttt{assert}s.
\end{enumerate}

The problem is that we cannot reconstruct the original arrays of
tuples from the tuples of arrays of internal \LO{}.  We cannot know
whether any tuple of arrays we encounter was originally an array of
tuples or not.  However, as long as the entry point of the program,
the \texttt{main} function, does not use arrays of tuples as argument
or return value, there should be no observable difference.  If
necessary, we could handle \texttt{main} on an ad-hoc basis to
preserve its original type.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis.tex"
%%% End: 
