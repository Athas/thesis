\documentclass{beamer}
\usepackage[english]{babel}
\usepackage{url}
\usepackage{listings}
\usepackage{adjustbox}
\usepackage{chronology}
\newcommand{\LO}{$\mathcal{L}_0$}

% Graphics
\usepackage{graphicx}

% Font
\usepackage{microtype}
% \usepackage[scaled]{beramono}
\usepackage{fontspec,xunicode}
\newfontfamily\sbmyriad{Myriad Pro Semibold}
\setsansfont{Myriad Pro}
\setmonofont{Myriad Pro}
\setbeamerfont{title}{family=\sbmyriad}
\setbeamerfont{frametitle}{family=\bf}


% Beamer theme settings
\usecolortheme{seagull}
\setbeamertemplate{itemize item}{\raisebox{0.8mm}{\rule{1.2mm}{1.2mm}}}
\usenavigationsymbolstemplate{} % no navigation buttons

\lstdefinelanguage{L0}
{keywords={fun,if,then,else,loop,do,map,reduce,filter,scan,redomap,mapT,reduceT,filterT,scanT,redomapT,transpose,reshape,iota,replicate,let},%
  sensitive=true,%
  comment=[l]{//},%
  string=[b]",%
  string=[b]'%
}

\lstset{
  language=L0
}

\title{Master's thesis defence}
\subtitle{Exploiting functional invariants to optimise parallelism:\\ A dataflow approach}
\author{Troels Henriksen}
\date{21. February 2014}
\institute{Computer Science\\
  University of Copenhagen}

\begin{document}
% Welcome
% Both a defence and this is what I do
\frame{\titlepage}

% % Nice diagram showing how the talk will progress
% \begin{frame}
%   \frametitle{Agenda}
%   \tableofcontents
% \end{frame}

\begin{frame}
  \frametitle{Free lunches}

  \begin{itemize}
  \item Moores law still in effect, and will be for a while..
  \item ... but we no longer get many increases in sequential
    performances.
  \item Modern performance increases are in the form of parallelism.
  \item The most parallel machines are massively parallel vector
    processors, with commodity GPUs being particularly interesting due
    to their ubiquity.
  \end{itemize}

\end{frame}

\begin{frame}
  \frametitle{GPGPU}

  \begin{itemize}
  \item GPUs were popularised in the 90s for graphics processing.
  \item Graphics is inherently parallel, so for cost reasons, the GPU
    hardware was very parallel as well.
  \item In roughly 2006, GPGPU began to take off with CUDA and then
    OpenCL.
  \item GPGPU is now widespread, but still very difficult.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{GPGPU, continued}

  \begin{itemize}
  \item OpenCL and CUDA both very low-level.
  \item No modularisation if you want performance.
  \item Libraries can contain optimised primitives... modular
    performance still tricky.
  \item So we need a language.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Language design}

  \begin{itemize}
  \item Three real-world financial computational kernels served to
    guide the design.  Two central questions:
    \begin{itemize}
    \item \textbf{What is the simplest language that permits a
        relatively straightforward translation of the financial
        programs, while still expressing algorithm invariants that
        enable the generation of efficient parallel code?}
    \item \textbf{What compiler optimizations would result in efficiency
        comparable to code hand-tuned for the specific hardware?}
    \end{itemize}
  \item We ended up on a functional language, \LO{}, supporting nested
    parallelism on regular arrays.
  \item Fusion is one of the most important optimisations.  ``Heroic
    Effort'' in an imperative language, but ``easy'' in a functional
    setting.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Hello, World!}

  \begin{lstlisting}
fun fact(int n) =
  if n = 0 then 1
           else n * fact(n-1)
\end{lstlisting}

\begin{lstlisting}
fun hofact(int n) =
  reduce(op *, 1, iota(n))
\end{lstlisting}

We have the following second-order array combinators (SOACs):
\textbf{reduce}, \textbf{map}, \textbf{scan}, \textbf{filter} and
\textbf{redomap}.

\end{frame}

\begin{frame}[fragile]
  \frametitle{In-place updates}

  The innermost part of a parallel loop may be a sequential
  computation.

  \begin{lstlisting}
fun [int] fib(int n) =
  // Create "empty" array.
  let arr = iota(n) in
  // Fill array with Fibonacci numbers.
  loop (arr) =
    for i < n-2 do
      let arr[i+2] = arr[i] + arr[i+1]
      in arr
  in arr
\end{lstlisting}

Runs in $O(n^{2})$ if the array update is not in-place!  Permitting
mutation of the array allows an asymptotic improvement to $O(n)$.

\end{frame}

\begin{frame}[fragile]
  \frametitle{Uniqueness types}

  A \textit{unique-typed function argument} is guaranteed not to be
  referenced again on any execution path following the function call.

  \begin{lstlisting}
  fun *[int] modify(*[int] a, int i, int x) =
    let a[i] <- a[i] + x in
    a
\end{lstlisting}

This runs in $O(1)$.

The return type is also unique -- this means that there are no other
references to the value.
\end{frame}

\begin{frame}
  \frametitle{Producer-consumer fusion}

  \begin{itemize}
  \item Fusion can reduce space requirements and optimise memory
    hierarchy overhead.
  \item Very hard in imperative languages, but much easier in
    functional languages.
  \item Based on recognising \textit{producer-consumer} pairs.
  \end{itemize}

As a simple case, we can fuse the two loops in
\[
\texttt{(map~$f$)~$\circ$~(map~$g$)}
\]
and get
\[
\texttt{map~$(f~\circ~g)$}
\]
\end{frame}

\begin{frame}
  \frametitle{Different approaches to fusion}

\begin{itemize}
\item Delayed arrays -- represent arrays as a function from the index
  space to the value space.
    \begin{itemize}
    \item Fusion is easy to implement - just function composition.
    \item Hard to avoid duplication of computation.
    \item Hard to analyse the memory access patterns of resulting code.
    \end{itemize}
\item Structural fusion with algebraic rewrite rules (our approach).
  \begin{itemize}
    \item Much harder to implement.
    \item Easy to avoid duplication of computation.
    \item Memory access patterns are immediately clear from code
      structure.
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Simple rewrite rules}

\begin{lstlisting}
let {x1, x2} = mapT(f, a1)
in  mapT(g, x1, y)
\end{lstlisting}
Fuses to...
\begin{lstlisting}
mapT(fn r (t1 a1e, t2 ye) =>
       let {x1e, x2e} = f(a1e)
       in  g(x1e, ye),
     a1, y )
\end{lstlisting}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Simple rewrite rules, continued}

\begin{center}
\begin{tabular}{rcl}
\texttt{map $\circ$ map}    & $\Rightarrow$ & \texttt{map} \\
\texttt{replicate $\circ$ \textit{soac}} & $\Rightarrow$ & \textit{soac} \\
\texttt{filter $\circ$ filter} & $\Rightarrow$ & \texttt{filter}  \\
\texttt{filter $\circ$ reduce} & $\Rightarrow$ & \texttt{reduce} $\dag$  \\
\texttt{map $\circ$ reduce} & $\Rightarrow$ & \texttt{reduce} $\ddag$ \\
\texttt{map $\circ$ scan} & $\Rightarrow$ & \texttt{scan} $\ddag$ \\
\end{tabular}
\end{center}

\begin{description}
\item[$\dag$] Only if consumer takes input from no other
  source.
\item[$\ddag$] Only if consumer takes input from no other source,
  \textit{and} types of producer inputs match types of producer
  outputs.
\end{description}

\end{frame}

\begin{frame}[fragile,t]
  \frametitle{  \texttt{redomap($f_{r}$, $f_{m}$, $x$, $e$)}}

  Not part of the external language, but useful for the fusion
  algebra.  Semantics is the same as \texttt{\tt foldl($f_{m}$, $x$, $e$)}.

  $(\texttt{reduce}\ \odot\ e)\ \circ\ (\texttt{map}\ f)$ can be
  transformed, via the list homomorphism promotion lemma, to an
  equivalent form:
  \[
  (\texttt{reduce}\ \odot\ e)\ \circ\ (\texttt{map}\ f)\
  {\equiv}\ \texttt{reduce}\ \odot\
  e\ \circ\ \texttt{map}\ ({\texttt{reduce}\ \odot\ e\ \circ\ \texttt{map}\ f})\ \circ\ \texttt{split}_{p}
  \]
  Hence, the \textit{inner} map-reduce can be rewritten as a left-fold:
  \[
  (\texttt{reduce}\ \odot\ e)\ \circ\ (\texttt{map}\ f)\
  {\equiv}\ \texttt{reduce}\ \odot\
  e\ \circ \texttt{map} \ ({\texttt{foldl}\ g\ e})\ \circ\ \texttt{split}_{p}
  \]
  Where $g$ is a function generated from the composition of $f$ and
  $\odot$.  It follows that it is sufficient to record either $\odot$
  and $f$, or $\odot$ and $g$. We choose the latter, because it allows
  a richer compositional algebra for fusion.  In particular, it allows
  us to fuse \texttt{reduce~$\circ$~map~$\circ$~filter} into a
  \texttt{redomap} without duplicating computation.
\end{frame}

\begin{frame}
\frametitle{\texttt{redomap} rewriting rules}

\begin{center}
\begin{tabular}{rcl}
\texttt{map $\circ$ reduce}    & $\Rightarrow$ & \texttt{redomap} \\
\texttt{filter $\circ$ reduce}    & $\Rightarrow$ & \texttt{redomap} \\
\texttt{map $\circ$ redomap}    & $\Rightarrow$ & \texttt{redomap} \\
\texttt{filter $\circ$ redomap}    & $\Rightarrow$ & \texttt{redomap} \\
\end{tabular}
\end{center}

The first two rules are derivable from the latter two, since
\texttt{reduce(f,x,e)} can be rewritten to \texttt{redomap(f,f,x,e)}.

\end{frame}

\begin{frame}
  \frametitle{Reducible dataflow graph}

  We say that a flow graph is T$_{1}$-T$_{2}$-reducible if it can be
  reduced to a single node by the following two transformations:

\begin{description}
  \item[T$_{1}$:] Remove an edge from a node to itself.

  \item[T$_{2}$:] Combine two nodes $m$ and $n$, where $m$ is the
    single predecessor of $n$, and $n$ is not the entry of the flow
    graph.
\end{description}

\begin{columns}
\begin{column}{6cm}
\includegraphics[width=6cm]{img/t1t2.pdf}\hfill
\end{column}
\begin{column}{4cm}
\LO{} always produces a reducible flow graph.
\end{column}
\end{columns}

\end{frame}

\begin{frame}
  \frametitle{Tupleless SOACs}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Fusion example}

  We will try to fuse the following program.

  \begin{lstlisting}
let {x1} = mapT(h1, x2) in
let {y1,y2,y3} = mapT(f1, x1, x2) in
let {z1,z2} = mapT(f2, y1, y2) in
let {q1,q2} = mapT(g,y3,z1,y2,y3) in
{mapT(h, q1, q2, z2, y1, y3),
 mapT(h2, x2)}
\end{lstlisting}

Note that some outputs are used multiple times as inputs to different
SOACs.

\end{frame}

\begin{frame}[t]
  \frametitle{Fusion example, continued}

  \centering
  \begin{columns}
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-1.pdf}
    \end{column}\hfill
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-2.pdf}
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}[t]
  \frametitle{Fusion example, continued}

  \centering
  \begin{columns}
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-2.pdf}
    \end{column}\hfill
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-3.pdf}
    \end{column}
  \end{columns}

  Fusion through rewrite rules is not a new idea - they are used by
  e.g.  GHC.  Their rules are expressed in terms of the \textit{syntax
    tree} however, whereas ours use the dataflow graph.  This is much
  more powerful, and permits us to fuse multiple consumers when
  possible without duplicating computation.

\end{frame}

\begin{frame}
  \frametitle{Evaluation}
\end{frame}

\begin{frame}
  \frametitle{Future Work}

  \begin{itemize}
  \item More precise aliasing analysis - track array rows as well.
  \item Fuse when a trivial amount of computation would be duplicated.
  \item Implement a parallel code generator.
  \end{itemize}
\end{frame}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-engine: luatex
%%% End:
