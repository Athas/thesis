% Notes:
% 
% 

\documentclass{beamer}
\usepackage[english]{babel}
\usepackage{url}
\usepackage{listings}
\usepackage{adjustbox}
\usepackage{chronology}
\newcommand{\LO}{$\mathcal{L}_0$}
\usepackage{amsmath}

% Graphics
\usepackage{graphicx}

% Font
\usepackage{paratype}
\setbeamerfont{frametitle}{family=\bf}


% Beamer theme settings
\usecolortheme{seagull}
\setbeamertemplate{itemize item}{\raisebox{0.8mm}{\rule{1.2mm}{1.2mm}}}
\usenavigationsymbolstemplate{} % no navigation buttons

\lstdefinelanguage{L0}
{keywords={fun,if,then,else,loop,do,map,reduce,filter,scan,redomap,mapT,reduceT,filterT,scanT,redomapT,transpose,reshape,iota,replicate,let, op},%
  sensitive=true,%
  comment=[l]{//},%
  string=[b]",%
  string=[b]'%
}

\lstset{
  language=L0
}

\title{Master's thesis defence}
\subtitle{Exploiting functional invariants to optimise parallelism:\\ A dataflow approach}
\author{Troels Henriksen (athas@sigkill.dk)}
\date{21. February 2014}
\institute{Computer Science\\
  University of Copenhagen}

\begin{document}

\frame{\titlepage}

\begin{frame}
  \frametitle{Free lunches}

  \centering
  \includegraphics[width=7cm]{img/CPU-Scaling.jpg}

  \begin{itemize}
  \item Moore's law still in effect, and will be for a while...
  \item ... but we no longer get many increases in sequential
    performance.
  \end{itemize}

\end{frame}

\begin{frame}
  \frametitle{So, what's on the menu?}

  \begin{itemize}
  \item Modern performance increases are in the form of parallelism.
  \item The most parallel machines are massively parallel vector
    processors, with commodity GPUs being particularly interesting due
    to their ubiquity.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{GPGPU}

  \begin{itemize}
  \item GPUs were popularised in the 90s for graphics processing.
  \item Graphics is inherently parallel, so for cost reasons, the GPU
    hardware was very parallel as well.
  \item In roughly 2006, GPGPU began to take off with CUDA and then
    OpenCL.
  \item GPGPU is now widespread, but still very difficult.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{GPGPU, continued}

  \begin{itemize}
  \item OpenCL and CUDA both very low-level.
  \item No modularisation if you want performance.
  \item Libraries can contain optimised primitives... modular
    performance still tricky.
  \item So we need a language.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Language design}

  \begin{itemize}
  \item Three real-world financial computational kernels served to
    guide the design.  Two central questions:
    \begin{itemize}
    \item \textbf{What is the simplest language that permits a
        relatively straightforward translation of the financial
        programs, while still expressing algorithm invariants that
        enable the generation of efficient parallel code?}
    \item \textbf{What compiler optimizations would result in efficiency
        comparable to code hand-tuned for the specific hardware?}
    \end{itemize}
  \item We ended up on a functional language, \LO{}, supporting nested
    parallelism on regular arrays.
  \item Fusion is one of the most important optimisations.  ``Heroic
    Effort'' in an imperative language, but ``easy'' in a functional
    setting.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Hello, World!}

  \begin{lstlisting}
fun fact(int n) =
  if n = 0 then 1
           else n * fact(n-1)
\end{lstlisting}

\begin{lstlisting}
fun hofact(int n) =
  reduce(op *, 1, iota(n))
\end{lstlisting}

We have the following second-order array combinators (SOACs):
\textbf{reduce}, \textbf{map}, \textbf{scan}, \textbf{filter} and
\textbf{redomap}.

\end{frame}

\begin{frame}[fragile]
  \frametitle{In-place updates}

  The innermost part of a parallel loop may be a sequential
  computation.

  \begin{lstlisting}
fun [int] fib(int n) =
  // Create "empty" array.
  let arr = iota(n) in
  // Fill array with Fibonacci numbers.
  loop (arr) =
    for i < n-2 do
      let upd = arr with
            [i+2] <- arr[i] + arr[i+1]
      in upd
  in arr
\end{lstlisting}

Runs in $O(n^{2})$ if the array update is not in-place!  Permitting
mutation of \texttt{arr} allows an asymptotic improvement to $O(n)$.

\end{frame}

\begin{frame}[fragile]
  \frametitle{In-place updates, continued}

  We must ensure that an array is not referenced after it has been
  \textit{consumed}:

  \begin{lstlisting}
let b = a with [i] <- v in // consumes 'a'
f(a,b)                     // Error!
\end{lstlisting}

Intraprocedurally, we can use aliasing analysis combined with standard
dataflow inspection to ensure that \texttt{a} is dead.  But what about
interprocedurally?

\end{frame}

\begin{frame}[fragile]
  \frametitle{Uniqueness types}

  A \textit{unique-typed function argument} is guaranteed not to be
  referenced again on any execution path following the function call.

  \begin{lstlisting}
  fun *[int] modify(*[int] a, int i, int x) =
    let b = a with [i] <- a[i] + x in
    b
\end{lstlisting}

\begin{itemize}
\item This runs in $O(1)$.

\item The return type is also unique -- this means that there are no
  other references to the value.

\item After the call \texttt{modify(a,i,x)}, \texttt{a} must not be
  used again.
\end{itemize}

\end{frame}

\begin{frame}
  Code snippets from benchmarks; they exist.  Show that in-place
  updates are used, and why (imperative loops, indirect indexing).
\end{frame}

\begin{frame}[fragile]
  \frametitle{Producer-consumer fusion}

  \begin{lstlisting}
let b = map(f, a) in
  // b = [f(a[0]), ..., f(a[n])]
let c = map(f, b) in
  // c = [f(b[0]), ..., f(b[n])]
\end{lstlisting}

Fused, these become:

\begin{lstlisting}
let c = map(f o g, a) in
  // c = [g(f(a[0])), ..., g(f(a[n]))]
\end{lstlisting}

\begin{columns}
  \begin{column}{0.5\textwidth}
    \begin{lstlisting}
for i = 0,n do
  b[i] = f(a[i])
for i = 0,n do
  c[i] = g(b[i])
\end{lstlisting}
  \end{column}
  \begin{column}{0.5\textwidth}
    \begin{lstlisting}
for i = 0,n do
  tmp = f(a[i])
  c[i] = tmp
\end{lstlisting}
  \end{column}
\end{columns}

\begin{itemize}
\item Reduces space requirements and lowers memory hierarchy overhead.
\item Based on recognising \textit{producer-consumer} pairs.
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Different approaches to fusion}

  \begin{itemize}
  \item Delayed arrays -- represent arrays as a function from the index
    space to the value space.
    \begin{itemize}
    \item Fusion is easy to implement - just function composition.
    \item Hard to avoid duplication of computation.
    \item Hard to analyse the memory access patterns of resulting code.
    \item Used in Accelerate, Repa, etc.
    \end{itemize}
  \item Structural fusion with algebraic rewrite rules.
    \begin{itemize}
    \item Much harder to implement.
    \item Easy to avoid duplication of computation.
    \item Memory access patterns are immediately clear from code
      structure.
    \item Used in GHC... and \LO{}!
    \end{itemize}
  \end{itemize}

  FIXME: multiple-consumer fusion example
\end{frame}

\begin{frame}
  zip/unzip is syntactis sugar eliminated by tuple transform. (NESL does this?)
\end{frame}

\begin{frame}[fragile]
  \frametitle{Simple rewrite rules}

  \begin{lstlisting}
let {x1, x2} = mapT(f, a1)
in  mapT(g, x1, y)
\end{lstlisting}
Fuses to...
\begin{lstlisting}
mapT(fn r (t1 a1e, t2 ye) =>
       let {x1e, x2e} = f(a1e)
       in  g(x1e, ye),
     a1, y )
\end{lstlisting}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Simple rewrite rules, continued}

  \begin{center}
    \begin{tabular}{rcl}
      \texttt{map $\circ$ map}    & $\Rightarrow$ & \texttt{map} \\
      \textit{soac} $\circ$ \texttt{replicate} & $\Rightarrow$ & \textit{soac} \\
      \texttt{filter $\circ$ filter} & $\Rightarrow$ & \texttt{filter}  \\
      \texttt{reduce $\circ$ filter} & $\Rightarrow$ & \texttt{reduce} $\dag$  \\
      \texttt{reduce $\circ$ map} & $\Rightarrow$ & \texttt{reduce} $\ddag$ \\
      \texttt{scan $\circ$ map} & $\Rightarrow$ & \texttt{scan} $\ddag$ \\
    \end{tabular}
  \end{center}

  \begin{description}
  \item[$\dag$] Only if consumer takes input from no other
    source.
  \item[$\ddag$] Only if consumer takes input from no other source,
    \textit{and} types of producer inputs match types of producer
    outputs.
  \end{description}

\end{frame}

\begin{frame}[fragile,t]
  \frametitle{  \texttt{redomap($f_{r}$, $f_{m}$, $x$, $e$)}}

  Not part of the external language, but useful for the fusion
  algebra.  Semantics is the same as \texttt{\tt foldl($f_{m}$, $x$, $e$)}.

  $(\texttt{reduce}\ \odot\ e)\ \circ\ (\texttt{map}\ f)$ can be
  transformed, via the list homomorphism promotion lemma, to an
  equivalent form:
  \begin{gather*}
    (\texttt{reduce}\ \odot\ e)\ \circ\ (\texttt{map}\ f)\ {\equiv}\\
    \texttt{reduce}\ \odot\
    e\ \circ\ \texttt{map}\ ({\texttt{reduce}\ \odot\ e\ \circ\ \texttt{map}\ f})\ \circ\ \texttt{split}_{p}
  \end{gather*}
  Hence, the \textit{inner} map-reduce can be rewritten as a left-fold:
  \[
  (\texttt{reduce}\ \odot\ e)\ \circ\ (\texttt{map}\ f)\
  {\equiv}\ \texttt{reduce}\ \odot\
  e\ \circ \texttt{map} \ ({\texttt{foldl}\ g\ e})\ \circ\ \texttt{split}_{p}
  \]
  Where $g$ is a function generated from the composition of $f$ and
  $\odot$.  It follows that it is sufficient to record either $\odot$
  and $f$, or $\odot$ and $g$. We choose the latter, because it allows
  a richer compositional algebra for fusion.  In particular, it allows
  us to fuse \texttt{reduce~$\circ$~map~$\circ$~filter} into a
  \texttt{redomap} without duplicating computation.
\end{frame}

\begin{frame}
  \frametitle{\texttt{redomap} rewriting rules}

  \begin{center}
    \begin{tabular}{rcl}
      \texttt{reduce $\circ$ map}    & $\Rightarrow$ & \texttt{redomap} \\
      \texttt{reduce $\circ$ filter}    & $\Rightarrow$ & \texttt{redomap} \\
      \texttt{redomap $\circ$ map}    & $\Rightarrow$ & \texttt{redomap} \\
      \texttt{redomap $\circ$ filter}    & $\Rightarrow$ & \texttt{redomap} \\
    \end{tabular}
  \end{center}

  The first two rules are derivable from the latter two, since
  \texttt{reduce(f,x,e)} can be rewritten to \texttt{redomap(f,f,x,e)}.

\end{frame}

\begin{frame}
  \frametitle{Reducible dataflow graph}

  We say that a flow graph is T$_{1}$-T$_{2}$-reducible if it can be
  reduced to a single node by the following two transformations:

  \begin{description}
  \item[T$_{1}$:] Remove an edge from a node to itself.

  \item[T$_{2}$:] Combine two nodes $m$ and $n$, where $m$ is the
    single predecessor of $n$, and $n$ is not the entry of the flow
    graph.
  \end{description}

  \begin{columns}
    \begin{column}{6cm}
      \includegraphics[width=6cm]{img/t1t2.pdf}\hfill
    \end{column}
    \begin{column}{4cm}
      \LO{} always produces a reducible flow graph.
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}
  \frametitle{Tupleless SOACs}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Fusion example}

  We will try to fuse the following program.

  \begin{lstlisting}
let {x1} = mapT(h1, x2) in
let {y1,y2,y3} = mapT(f1, x1, x2) in
let {z1,z2} = mapT(f2, y1, y2) in
let {q1,q2} = mapT(g,y3,z1,y2,y3) in
{mapT(h, q1, q2, z2, y1, y3),
 mapT(h2, x2)}
\end{lstlisting}

Note that some outputs are used multiple times as inputs to different
SOACs.

\end{frame}

\begin{frame}[t]
  \frametitle{Fusion example, continued}

  \centering
  \begin{columns}
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-1.pdf}
    \end{column}\hfill
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-2.pdf}
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}[t]
  \frametitle{Fusion example, continued}

  \centering
  \begin{columns}
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-2.pdf}
    \end{column}\hfill
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-3.pdf}
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}[t]
  \frametitle{Fusion example, continued}

  \centering
  \begin{columns}
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-3.pdf}
    \end{column}\hfill
    \begin{column}[T]{0.48\textwidth}
      \includegraphics[width=5cm]{img/fusion-4.pdf}
    \end{column}
  \end{columns}

  Fusion through rewrite rules is not a new idea - they are used by
  e.g.  GHC.  Their rules are expressed in terms of the \textit{syntax
    tree} however, whereas ours use the dataflow graph.  This is much
  more powerful, and permits us to fuse multiple consumers when
  possible without duplicating computation.

\end{frame}

\begin{frame}
  \frametitle{Evaluation}

  We tested the approach on the real-world kernels; got some results.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Future Work}

  \begin{itemize}
  \item More precise aliasing analysis - track array rows as well.
    \begin{itemize}
    \item This should work:
      \begin{lstlisting}
let r = replace(a[j], j, x) in
let b = a with [j] <- r in
...
\end{lstlisting}
\end{itemize}

\item Fuse when a trivial amount of computation would be duplicated.
\item Implement a parallel code generator.
\end{itemize}
\end{frame}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% End:
